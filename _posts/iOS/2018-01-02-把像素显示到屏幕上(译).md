---
layout: article
title: "把像素显示到屏幕上(译)"
categories: iOS
excerpt: "如何把一个像素显示到屏幕上？有很多种方法，这些方法包含不同的framework和很多不同的函数和方法的组合。在这里，我们将讲述一些发生在幕后的事情。"
ads: true
share: false
image:
---

**By [Daniel Eggert](https://twitter.com/danielboedewadt)** 

[原文网址](https://www.objc.io/issues/3-views/moving-pixels-onto-the-screen/)

如何把一个像素显示到屏幕上？有很多种方法，这些方法包含不同的framework和很多不同的函数和方法的组合。在这里，我们将讲述一些发生在幕后的事情。我们希望这篇文章能帮你理解当你需要决定调试和修复性能问题的时候哪个API最好。这篇文章虽然是以iOS为例，但是大多数讲的内容也同时适用于OS X。

## 图形堆栈

当像素要显示到屏幕上时，许多事情在幕后悄悄进行着。但是一旦这些像素已经在屏幕上了，每个像素由三个元素组成：红、黄、蓝。三种单独的颜色单元以不同的强度叠加显示，组成一个特定颜色的像素。你的iPhone5，液晶显示屏有1,136*640 = 727,040个像素，也就是2,181,120个颜色单元。一个15英寸的retina屏幕的话，这个数字将会超过15500000。整儿图形堆栈一起动作来确保每个颜色单元显示正确的强度。当你滚动屏幕时，所有的这些鼠疫百万计的像素每秒要更新60次，这是一个巨大的工作量。

### 软件部分

简单的看，软件上的栈看起来就像这样：

![](https://www.objc.io/images/issue-3/pixels-software-stack@2x-1ae69f5a.png)

Display的上面是GPU（graphics processing unit）。GPU是一个专门为并行图形计算设计的高并发的处理单元。这样才能更新大量的像素点，并把他们显示在屏幕上。它的并行特性也使得它可以很有效地合成纹理。我们一会儿会更详细的讨论合成纹理。关键是GPU是专门设计的，因此在处理一些类似工作时更加高效，例如它处理图像时比cpu更快，消耗的能量更少。CPU有着广泛的用途，可以做很多不同的事情，但是例如合成纹理的话，还是GPU更快。

GPU驱动是一段可以直接和GPU对话的代码。它让不同类型的GPU对下一层OpenGL/OpenGL ES表现的更加统一。

OpenGL(Open Graphics Libiary) 是一个渲染2D或者3D图像的API。GPU是一个非常专业化的硬件，OpenGL和GPU非常紧密的合作来发挥GPU的计算特性和实现硬件加速渲染。对于很多人来说，OpenGL或许看起来非常底层，但是它在1992年发布时，就是第一个和GPU对话的主要的标准方法，这是一个巨大的进步，因为程序员再也不用为了各个GPU重写他们的应用。

在OpenGL上一层，有点儿分叉。在iOS系统上，几乎所有的事情都是通过Core Animation，在OS X上，Core Graphics 绕过Core Animation的情况非常常见。对于一些专门化的应用来说，尤其是游戏，app 可以直接和OpenGL/OpenGL ES对话。有点儿让人有点儿迷惑的是Core Animation 的部分渲染使用了 Core Graphics，像AVFoundation、Core Image和其他框架这样的框架可以将所有东西混合起来。

要记住一件事情，GPU是一个非常强大的进行图像处理的硬件，在显示像素上处于中心地位。它和CPU连接。在硬件层面，总线连接GPU和CPU，像OpenGL, Core Animation和 Core Graphics这些框架协调GPU和CPU之间的数据传输。为了让像素点显示在屏幕上，有些处理需要在CPU上进行，然后处理过的数据传输给GPU，GPU再做处理，最终像素点显示在屏幕上。

这个过程的每个部分都有自己的挑战的部分，在这个过程中也会有一些权衡。

### 硬件部分

![](https://www.objc.io/images/issue-3/pixels,%20hardware@2x-861825d9.png)

一个非常简单的挑战看起来像这样：GPU有一些由每一帧合成的纹理(位图)，每个纹理都占用VRAM(Vedio RAM)，因此GPU可以保留多少纹理是有限制的。即使GPU在合成纹理方面非常高效，但是总有一些更加复杂的合成任务，而GPU在16.7ms(1/60s)的时间内处理多少工作也是有限制的，不可能是无限的。

另一个挑战是把要处理的数据给到GPU。为了能让GPU访问到数据，需要把数据从RAM转移到VRAM里面，也就是把数据上传到GPU。这似乎微不足道，单对于大量要处理的纹理来说就会是非常耗时的操作。

最后，你的应用程序是在CPU上跑的，你会告诉CPU从你的bundle文件中加载一个PNG图片，并解压它，这些都发生在CPU上。当你想要显示解压的图片时，就需要上传到GPU。像显示文本这样平凡的事情对于CPU来说是非常复杂的任务，它要使Core Text 和 Core Graphics框架紧密结合来生成文本的位图，然后以纹理的格式上传给GPU去显示。当你在屏幕上拖动或移动这个文本，这个纹理可以重用，CPU只需要告诉GPU新的位置就可以了，因此GPU可以重用已经存在的纹理。CPU不需要重新渲染文本，也不需要重新上传位图。

以上说明了其中的一些复杂性。了解了这部分概述，我们将深入探讨其中的一些技术。

## 合成纹理

在图形世界中`合成`是一个术语，用来描述不同的位图是如何组合在一起来创建你在屏幕上看到的最终图像。从很多方面来说，显而易见，让你很容易忘记涉及的复杂性和计算。

让我们忽略一些更深奥的案例，假定所有屏幕上的内容都是纹理。纹理是一个RGBA值的矩形区域，也就是说，对于每个像素都有红、绿、蓝颜色值和透明度，在Core Animation里，这叫做`CALayer`。

在这个稍微简化的设置下，每个layer都是一个纹理，所有的这些纹理都是以某种方式相互叠加。对于屏幕上的每个像素来说，GPU需要弄清楚如何混合这些纹理得到这个像素最终的RGB值，这就是`合成`。

如果我们在屏幕上只有一个单一的纹理，并且和屏幕大小相等，每个屏幕上的像素对应纹理上的像素，纹理的像素最终成为屏幕的像素。

如果我们有第二个纹理放在第一个纹理的上面，GPU就不得不合成这个纹理到第一个上。我们假定两个纹理是像素对齐的，并且使用正常的混合模式，用下面的公式计算每个像素的颜色：

```
R = S + D * (1 - Sa)
```

结果颜色Result等于Source颜色(上层)加Destination颜色(下层)乘以1减去Source颜色的alpha值。

很明显，这里发生了很多事情，让我们再假定一下所有的纹理都是不透明的，也即是alpha=1，如果destination纹理是蓝色（RGB = 0，0，1），source纹理是红色（RGB = 1，0，0），因为Sa=1，所以`R = S`,结果颜色是红色，和你的期望值相符。

如果Source（上层）layer的透明度是50%，S的RGB值将会是（0.5，0，0），公式将会变成这样：

```
                       0.5   0               0.5
R = S + D * (1 - Sa) = 0   + 0 * (1 - 0.5) = 0
                       0     1               0.5
```

我们最终得到了一个RGB值(0.5,0,0.5)，一个饱和的紫色，这是你在把透明红色和蓝色背景混合在一起时的第一感觉。

目前为止我们只计算了一个纹理的单个像素和另一个纹理的单个像素的合成，而GPU则需要计算所有纹理的所有像素合成。正如你知道的，大多数的app有很多的layers，所有的纹理都需要合成到一起，即使GPU是一个高度优化的专门做这种事情的硬件，这也让GPU变得很忙。

### 不透明 VS. 透明度(Opaque vs. Transparent)

当Source纹理完全不透明时，生成的像素和Source纹理一样，这会节省GPU很多工作，因为它可以简单地复制Source纹理的像素值。但是，GPU无法分辨纹理中是否有像素不透明，只有作为程序员的你知道你向`CALayer`里放了什么。这就是`CALayer`有一个叫做`opaque`属性的原因，如果`opaque`是`YES`,GPU将会忽略下面的层直接从这个layer复制纹理，这节省了GPU大量的工作。在Instruments选项中`color blended layers`让你可以看到那些layers被标记为非不透明的，这样的layer需要混合。合成不透明layer消耗更少，因为计算的比较少。

因此，如果你知道你的layer是不透明的，把`opaque`设置成`YES`。如果你要加载一个没有alpha通道的图片然后显示到`UIImageView`，这是一个自动的过程。注意，一个没有alpha通道的图片和一个alpha为100%的图片有着巨大的差异，后者情况下，Core Animation需要假定或许有一些像素的alpha值不是100%，这就需要检验和计算。在`Finder`中，你可以通过`显示简介`中的`更多信息`中的`alpha通道`来判断图片是否包含alpha通道。

### 像素对齐和不对齐

到目前为止，我们已经研究了那些像素对齐的layers的显示，当所有的layer都是像素对齐的时候我们只需要相对简单的数学运算。无论何时GPU都要弄清楚屏幕上的像素应该是什么颜色，它只需要看在屏幕上的所有layers的像素，并合成他们，或者当最上层的layer是不透明时，只需要复制最上层的layer的纹理。

我们说一个layer是像素对齐的是指layer上所有的像素都和屏幕上的像素完美对齐。有以下两个原因会导致不是这种像素对齐的情况：第一、缩放，当一个纹理放大或者缩小的时候，纹理的像素点就无法和屏幕的像素点对齐；***第二、纹理的来源不是像素边界***。

在这两种情况下，GPU需要做额外的数学计算。它要把多个像素点混合计算出一个值用来合成。当像素对齐的时候，GPU做的工作就少很多。

再次，`Core Animation Instrument`有一个叫`color misaligned images`的选项，当像素不对齐时会告诉你是哪个layer实例。

### 蒙层(Mask)

一个layer有一个与之关联的蒙层，这个蒙层是一个在合成到下层layer之前应用到layer的像素上的alpha值的位图。当你设置layer的圆角半径时，实际上你是在那个layer上设置了一个蒙层。也可以指定任意一个蒙层，例如一个字母A形状的蒙层。只有这个蒙层上的layer的内容部分才会被渲染。

### 离屏渲染(Offscreen Rendering)

离屏渲染能够被`Core Animation`或者你的应用程序自动触发。离屏渲染是指合成/渲染layer树到一个新的buffer(不在屏幕上)，然后再把这个buffer里的内容渲染到屏幕上。

当合成计算代价太高的时候你或许会强制开启离屏渲染，这是缓存合成的纹理的一种方法。如果你的渲染树(所有纹理和它们如何组合在一起)非常复杂，你可以强制使用离屏渲染来缓存这些合成好的layer，然后把缓存的内容合成显示到屏幕上。

如果你的app的页面有很多layer结合在一起的，GPU通常需要重新合成所有的layer。当使用离屏渲染的时候，GPU首先将这些层组合成一个基于新纹理的位图缓存，然后把新纹理显示到屏幕上。现在当这些layers要一起显示的时候，GPU使用这个位图缓存，从而减少工作量。值得注意的是，只有在这些layers不发生改变的时候才适用，一旦这些layers发生了改变，GPU需要重新生成位图缓存。你可以通过设置shouldRasterize来触发这个行为。

这里就需要有一个权衡，一方面，离屏渲染会让渲染变慢，GPU需要做一个额外的步骤来创建一个offscreen缓冲区，特别的，如果它不能重用这个位图，做的缓存就浪费精力了。如果缓存的位图能够重用的话，GPU就减负了。你必须测量GPU利用率和帧速率来确定离屏渲染是否对你有帮助。

离屏渲染也可能产生副作用。如果你直接或间接给一个layer加一个蒙层mask，Core Animation被强制使用离屏渲染来增加这个蒙层mask。这增加了GPU的负担。通常情况下layer本来是可以直接渲染到帧缓冲区（屏幕）。

Instruments的Core Animation工具有一个叫做`Color Offscreen-Rendered Yellow`的选项，它会把使用离屏缓冲区渲染的区域染成黄色(在模拟器上同样适用)。确保把`Color Hits Green and Misses Red`选项也勾上。绿色表示离屏缓冲区被重用，红色表示离屏缓冲区被重新创建。

通常情况下，你想要避免离屏渲染，因为代价太高了。直接把layers合成到帧缓冲区比先创建已经离屏缓冲区，渲染到里面，再把离屏缓冲区的内容渲染到帧缓冲区(屏幕)代价更小。后者有两次高代价的上下文切换：把上下文切换到离屏缓冲区，然后再把上下文切换到帧缓冲区。

因此，当你把`Color Offscreen-Rendered Yellow`选项打开，然后看到了黄色，就可以理解为一个警告，警告你有地方使用了离屏渲染了。但这并不一定是坏事，如果Core Animation能够重用离屏渲染的缓存，它可以提高性能。当layers没有改变时就可以重用。

还要注意的是，栅格化层(rasterized layers)的空间是有限的,Apple暗示栅格化层(rasterized layers)/离屏缓冲区的屏幕尺寸大约是屏幕的两倍。

如果你使用layer的方式导致了离屏渲染，你最好还是要尽量避免。使用蒙层mask、给layer谁知一个圆角半径或者使用阴影都会导致离屏渲染。

对于蒙层mask来说，有圆角半径，`clipsToBounds / masksToBounds`,这样的蒙层你或许可以简单的创建一个刚好包含这些的内容，例如一个刚好有圆角的图片。和以前一样，你需要权衡利弊。如果你想使用一个矩形的蒙层，你可以用`contentsRect`代替蒙层mask。

如果你把`shouldRasterize`设置为YES，记得将`rasterizationScale`设置为`contentsScale`。

### 更多关于合成(Compositing)

和往常一样，维基百科上有更多关于[alpha合成](https://en.wikipedia.org/wiki/Alpha_compositing)的数学方面的背景知识。我们将会在后续讨论[像素](https://www.objc.io/issues/3-views/moving-pixels-onto-the-screen/#pixels)的时候更深入的讨论如何在内存中表示红色、绿色、蓝色和alpha。

### OS X

如果你在开发OS X上的应用，你会发现上面提到的大多数的调试选项在另一个独立的叫做`Quartz Debug`的app上，不在Instruments里面。`Quartz Debug`是`Graphics Tools`的一部分，需要在[开发者网站](https://developer.apple.com/downloads/)上单独下载。