---
layout: article
title: "把像素显示到屏幕上(译)"
categories: iOS
excerpt: "如何把一个像素显示到屏幕上？有很多种方法，这些方法包含不同的framework和很多不同的函数和方法的组合。在这里，我们将讲述一些发生在幕后的事情。"
ads: true
share: false
image:
---

**By [Daniel Eggert](https://twitter.com/danielboedewadt)** 

[原文网址](https://www.objc.io/issues/3-views/moving-pixels-onto-the-screen/)

如何把一个像素显示到屏幕上？有很多种方法，这些方法包含不同的framework和很多不同的函数和方法的组合。在这里，我们将讲述一些发生在幕后的事情。我们希望这篇文章能帮你理解当你需要决定调试和修复性能问题的时候哪个API最好。这篇文章虽然是以iOS为例，但是大多数讲的内容也同时适用于OS X。

## 图形堆栈

当像素要显示到屏幕上时，许多事情在幕后悄悄进行着。但是一旦这些像素已经在屏幕上了，每个像素由三个元素组成：红、黄、蓝。三种单独的颜色单元以不同的强度叠加显示，组成一个特定颜色的像素。你的iPhone5，液晶显示屏有1,136*640 = 727,040个像素，也就是2,181,120个颜色单元。一个15英寸的retina屏幕的话，这个数字将会超过15500000。整儿图形堆栈一起动作来确保每个颜色单元显示正确的强度。当你滚动屏幕时，所有的这些鼠疫百万计的像素每秒要更新60次，这是一个巨大的工作量。

### 软件部分

简单的看，软件上的栈看起来就像这样：

![](https://www.objc.io/images/issue-3/pixels-software-stack@2x-1ae69f5a.png)

Display的上面是GPU（graphics processing unit）。GPU是一个专门为并行图形计算设计的高并发的处理单元。这样才能更新大量的像素点，并把他们显示在屏幕上。它的并行特性也使得它可以很有效地合成纹理。我们一会儿会更详细的讨论合成纹理。关键是GPU是专门设计的，因此在处理一些类似工作时更加高效，例如它处理图像时比cpu更快，消耗的能量更少。CPU有着广泛的用途，可以做很多不同的事情，但是例如合成纹理的话，还是GPU更快。

GPU驱动是一段可以直接和GPU对话的代码。它让不同类型的GPU对下一层OpenGL/OpenGL ES表现的更加统一。

OpenGL(Open Graphics Libiary) 是一个渲染2D或者3D图像的API。GPU是一个非常专业化的硬件，OpenGL和GPU非常紧密的合作来发挥GPU的计算特性和实现硬件加速渲染。对于很多人来说，OpenGL或许看起来非常底层，但是它在1992年发布时，就是第一个和GPU对话的主要的标准方法，这是一个巨大的进步，因为程序员再也不用为了各个GPU重写他们的应用。

在OpenGL上一层，有点儿分叉。在iOS系统上，几乎所有的事情都是通过Core Animation，在OS X上，Core Graphics 绕过Core Animation的情况非常常见。对于一些专门化的应用来说，尤其是游戏，app 可以直接和OpenGL/OpenGL ES对话。有点儿让人有点儿迷惑的是Core Animation 的部分渲染使用了 Core Graphics，像AVFoundation、Core Image和其他框架这样的框架可以将所有东西混合起来。

要记住一件事情，GPU是一个非常强大的进行图像处理的硬件，在显示像素上处于中心地位。它和CPU连接。在硬件层面，总线连接GPU和CPU，像OpenGL, Core Animation和 Core Graphics这些框架协调GPU和CPU之间的数据传输。为了让像素点显示在屏幕上，有些处理需要在CPU上进行，然后处理过的数据传输给GPU，GPU再做处理，最终像素点显示在屏幕上。

这个过程的每个部分都有自己的挑战的部分，在这个过程中也会有一些权衡。

### 硬件部分

![](https://www.objc.io/images/issue-3/pixels,%20hardware@2x-861825d9.png)

一个非常简单的挑战看起来像这样：GPU有一些由每一帧合成的纹理(位图)，每个纹理都占用VRAM(Vedio RAM)，因此GPU可以保留多少纹理是有限制的。即使GPU在合成纹理方面非常高效，但是总有一些更加复杂的合成任务，而GPU在16.7ms(1/60s)的时间内处理多少工作也是有限制的，不可能是无限的。

另一个挑战是把要处理的数据给到GPU。为了能让GPU访问到数据，需要把数据从RAM转移到VRAM里面，也就是把数据上传到GPU。这似乎微不足道，单对于大量要处理的纹理来说就会是非常耗时的操作。

最后，你的应用程序是在CPU上跑的，你会告诉CPU从你的bundle文件中加载一个PNG图片，并解压它，这些都发生在CPU上。当你想要显示解压的图片时，就需要上传到GPU。像显示文本这样平凡的事情对于CPU来说是非常复杂的任务，它要使Core Text 和 Core Graphics框架紧密结合来生成文本的位图，然后以纹理的格式上传给GPU去显示。当你在屏幕上拖动或移动这个文本，这个纹理可以重用，CPU只需要告诉GPU新的位置就可以了，因此GPU可以重用已经存在的纹理。CPU不需要重新渲染文本，也不需要重新上传位图。

以上说明了其中的一些复杂性。了解了这部分概述，我们将深入探讨其中的一些技术。

## 合成纹理

在图形世界中`合成`是一个术语，用来描述不同的位图是如何组合在一起来创建你在屏幕上看到的最终图像。从很多方面来说，显而易见，让你很容易忘记涉及的复杂性和计算。

让我们忽略一些更深奥的案例，假定所有屏幕上的内容都是纹理。纹理是一个RGBA值的矩形区域，也就是说，对于每个像素都有红、绿、蓝颜色值和透明度，在Core Animation里，这叫做`CALayer`。

在这个稍微简化的设置下，每个layer都是一个纹理，所有的这些纹理都是以某种方式相互叠加。对于屏幕上的每个像素来说，GPU需要弄清楚如何混合这些纹理得到这个像素最终的RGB值，这就是`合成`。

如果我们在屏幕上只有一个单一的纹理，并且和屏幕大小相等，每个屏幕上的像素对应纹理上的像素，纹理的像素最终成为屏幕的像素。

如果我们有第二个纹理放在第一个纹理的上面，GPU就不得不合成这个纹理到第一个上。我们假定两个纹理是像素对齐的，并且使用正常的混合模式，用下面的公式计算每个像素的颜色：

```
R = S + D * (1 - Sa)
```

结果颜色Result等于Source颜色(上层)加Destination颜色(下层)乘以1减去Source颜色的alpha值。

很明显，这里发生了很多事情，让我们再假定一下所有的纹理都是不透明的，也即是alpha=1，如果destination纹理是蓝色（RGB = 0，0，1），source纹理是红色（RGB = 1，0，0），因为Sa=1，所以`R = S`,结果颜色是红色，和你的期望值相符。

如果Source（上层）layer的透明度是50%，S的RGB值将会是（0.5，0，0），公式将会变成这样：

```
                       0.5   0               0.5
R = S + D * (1 - Sa) = 0   + 0 * (1 - 0.5) = 0
                       0     1               0.5
```

我们最终得到了一个RGB值(0.5,0,0.5)，一个饱和的紫色，这是你在把透明红色和蓝色背景混合在一起时的第一感觉。

目前为止我们只计算了一个纹理的单个像素和另一个纹理的单个像素的合成，而GPU则需要计算所有纹理的所有像素合成。正如你知道的，大多数的app有很多的layers，所有的纹理都需要合成到一起，即使GPU是一个高度优化的专门做这种事情的硬件，这也让GPU变得很忙。

### 不透明 VS. 透明度(Opaque vs. Transparent)

当Source纹理完全不透明时，生成的像素和Source纹理一样，这会节省GPU很多工作，因为它可以简单地复制Source纹理的像素值。但是，GPU无法分辨纹理中是否有像素不透明，只有作为程序员的你知道你向`CALayer`里放了什么。这就是`CALayer`有一个叫做`opaque`属性的原因，如果`opaque`是`YES`,GPU将会忽略下面的层直接从这个layer复制纹理，这节省了GPU大量的工作。在Instruments选项中`color blended layers`让你可以看到那些layers被标记为非不透明的，这样的layer需要混合。合成不透明layer消耗更少，因为计算的比较少。

因此，如果你知道你的layer是不透明的，把`opaque`设置成`YES`。如果你要加载一个没有alpha通道的图片然后显示到`UIImageView`，这是一个自动的过程。注意，一个没有alpha通道的图片和一个alpha为100%的图片有着巨大的差异，后者情况下，Core Animation需要假定或许有一些像素的alpha值不是100%，这就需要检验和计算。在`Finder`中，你可以通过`显示简介`中的`更多信息`中的`alpha通道`来判断图片是否包含alpha通道。

### 像素对齐和不对齐

到目前为止，我们已经研究了那些像素对齐的layers的显示，当所有的layer都是像素对齐的时候我们只需要相对简单的数学运算。无论何时GPU都要弄清楚屏幕上的像素应该是什么颜色，它只需要看在屏幕上的所有layers的像素，并合成他们，或者当最上层的layer是不透明时，只需要复制最上层的layer的纹理。

我们说一个layer是像素对齐的是指layer上所有的像素都和屏幕上的像素完美对齐。有以下两个原因会导致不是这种像素对齐的情况：第一、缩放，当一个纹理放大或者缩小的时候，纹理的像素点就无法和屏幕的像素点对齐；***第二、纹理的来源不是像素边界***。

在这两种情况下，GPU需要做额外的数学计算。它要把多个像素点混合计算出一个值用来合成。当像素对齐的时候，GPU做的工作就少很多。

再次，`Core Animation Instrument`有一个叫`color misaligned images`的选项，当像素不对齐时会告诉你是哪个layer实例。

### 蒙层(Mask)

一个layer有一个与之关联的蒙层，这个蒙层是一个在合成到下层layer之前应用到layer的像素上的alpha值的位图。当你设置layer的圆角半径时，实际上你是在那个layer上设置了一个蒙层。也可以指定任意一个蒙层，例如一个字母A形状的蒙层。只有这个蒙层上的layer的内容部分才会被渲染。

### 离屏渲染(Offscreen Rendering)

离屏渲染能够被`Core Animation`或者你的应用程序自动触发。离屏渲染是指合成/渲染layer树到一个新的buffer(不在屏幕上)，然后再把这个buffer里的内容渲染到屏幕上。

当合成计算代价太高的时候你或许会强制开启离屏渲染，这是缓存合成的纹理的一种方法。如果你的渲染树(所有纹理和它们如何组合在一起)非常复杂，你可以强制使用离屏渲染来缓存这些合成好的layer，然后把缓存的内容合成显示到屏幕上。